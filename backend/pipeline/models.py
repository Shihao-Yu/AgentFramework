"""
Pipeline data models.

These models represent the data structures used in the ticket-to-knowledge pipeline.
"""

from datetime import datetime
from typing import Optional, List, Dict, Any
from enum import Enum
from pydantic import BaseModel, Field


class PipelineDecision(str, Enum):
    """Pipeline decision for a ticket."""
    
    SKIP = "skip"  # Near-duplicate, skip entirely
    NEW = "new"  # Create new knowledge item (goes to staging)
    MERGE = "merge"  # Merge with existing item (goes to staging)
    ADD_VARIANT = "add_variant"  # Add as variant to existing item (direct insert)


class TicketData(BaseModel):
    """
    Input ticket data from source system.
    
    This is an abstract representation. Actual implementation depends on
    your ticket source (ClickHouse, Zendesk, etc.).
    """
    
    ticket_id: str
    subject: str
    body: str
    resolution: Optional[str] = None
    closure_notes: Optional[str] = None
    created_at: datetime
    resolved_at: Optional[datetime] = None
    category: Optional[str] = None
    subcategory: Optional[str] = None
    tags: List[str] = Field(default_factory=list)
    priority: Optional[str] = None
    agent_id: Optional[str] = None
    
    # Metadata
    source: str = "unknown"
    raw_data: Optional[Dict[str, Any]] = None


class SimilarItem(BaseModel):
    """A similar existing knowledge item found during search."""
    
    id: int
    title: str
    content: Dict[str, Any]
    knowledge_type: str
    similarity: float
    tags: List[str] = Field(default_factory=list)


class AnalysisResult(BaseModel):
    """
    Result of analyzing a ticket for knowledge extraction.
    
    Generated by the LLM during ticket analysis.
    """
    
    # Extracted content
    title: str
    question: str
    answer: str
    summary: Optional[str] = None
    
    # Classification
    knowledge_type: str = "faq"
    suggested_tags: List[str] = Field(default_factory=list)
    category_slug: Optional[str] = None
    
    # Quality metrics
    confidence: float = Field(ge=0, le=1)
    is_actionable: bool = True
    quality_notes: Optional[str] = None
    
    # Decision support
    decision: Optional[PipelineDecision] = None
    merge_target_id: Optional[int] = None
    merge_reasoning: Optional[str] = None


class PipelineResult(BaseModel):
    """Result of processing a single ticket through the pipeline."""
    
    ticket_id: str
    decision: PipelineDecision
    
    # Processing details
    analysis: Optional[AnalysisResult] = None
    similar_items: List[SimilarItem] = Field(default_factory=list)
    top_similarity: Optional[float] = None
    
    # Outcome
    staging_id: Optional[int] = None  # If NEW or MERGE
    variant_id: Optional[int] = None  # If ADD_VARIANT
    skipped_reason: Optional[str] = None  # If SKIP
    
    # Metadata
    processed_at: datetime = Field(default_factory=datetime.utcnow)
    processing_time_ms: Optional[int] = None
    error: Optional[str] = None


class PipelineStats(BaseModel):
    """Statistics for a pipeline run."""
    
    run_id: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    
    # Counts
    total_tickets: int = 0
    processed: int = 0
    skipped: int = 0
    new_items: int = 0
    merged_items: int = 0
    variants_added: int = 0
    errors: int = 0
    
    # Quality metrics
    avg_confidence: float = 0.0
    avg_similarity: float = 0.0
    
    # Performance
    avg_processing_time_ms: float = 0.0


class PipelineConfig(BaseModel):
    """Configuration for a pipeline run."""
    
    # Similarity thresholds
    similarity_skip_threshold: float = 0.95
    similarity_variant_threshold: float = 0.85
    similarity_merge_threshold: float = 0.70
    
    # Quality thresholds
    confidence_threshold: float = 0.7
    min_body_length: int = 30
    min_resolution_length: int = 30
    
    # Processing limits
    batch_size: int = 50
    max_similar_items: int = 5
    
    # Feature flags
    auto_add_variants: bool = True
    require_review_for_merge: bool = True
    dry_run: bool = False
